{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Diabetes_Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1GnKHfG5J4D6jpn-KpNxAgWbqB4JDZGmE",
      "authorship_tag": "ABX9TyNEonP+HszRsPMgdiHqt+5u"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8LSXWatuVsX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Deep Learning/Datasets/diabetes (2).csv\")"
      ],
      "metadata": {
        "id": "PYoiS-A2w6mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WAQbT9CVx0BB",
        "outputId": "b61d8279-6ea1-4ab6-8d6d-1ecf7179872e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db2444ea-12d3-424f-b5ed-88989e1d9c1a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db2444ea-12d3-424f-b5ed-88989e1d9c1a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db2444ea-12d3-424f-b5ed-88989e1d9c1a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db2444ea-12d3-424f-b5ed-88989e1d9c1a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "76qzYh0Fx1t7",
        "outputId": "1a13ab89-deb0-48c9-88ab-9ed98a751abf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "763           10      101             76             48      180  32.9   \n",
              "764            2      122             70             27        0  36.8   \n",
              "765            5      121             72             23      112  26.2   \n",
              "766            1      126             60              0        0  30.1   \n",
              "767            1       93             70             31        0  30.4   \n",
              "\n",
              "     DiabetesPedigreeFunction  Age  Outcome  \n",
              "763                     0.171   63        0  \n",
              "764                     0.340   27        0  \n",
              "765                     0.245   30        0  \n",
              "766                     0.349   47        1  \n",
              "767                     0.315   23        0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-15bd4113-336b-4174-94cd-f484fdb6cefe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15bd4113-336b-4174-94cd-f484fdb6cefe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-15bd4113-336b-4174-94cd-f484fdb6cefe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-15bd4113-336b-4174-94cd-f484fdb6cefe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysaZsWwFx3fW",
        "outputId": "8dfe1cdf-d331-464f-b23f-542cdd261c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
              "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZVuLTQfyv6E",
        "outputId": "6d7b0c16-7b26-4e33-9486-bf78125812da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = data.values\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "print(X)\n",
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daShMGFuzsHc",
        "outputId": "b92ffba5-2978-4f49-8c7c-e7d340764b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
            " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
            " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
            " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
            " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1S7h-OE0jWN",
        "outputId": "71519769-ba37-4993-c5c1-85d76a2af986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "encoded_y = np_utils.to_categorical(Y)\n",
        "encoded_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2yKo4bu13mK",
        "outputId": "ed48d5c8-d7f9-40ca-f9e0-209c23279c4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_training, X_testing, Y_training, Y_testing = train_test_split(X_scale, encoded_y, test_size=0.2, random_state=10)\n",
        "X_training, X_valid, Y_training, Y_valid = train_test_split(X_training, Y_training, test_size=0.2, random_state=10)\n",
        "print(len(X_training))\n",
        "print(len(X_testing))\n",
        "print(len(X_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odYRs61w37av",
        "outputId": "d0670a26-ffe8-4740-f6c7-ad392dd0f13f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "491\n",
            "154\n",
            "123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "J7OTUdlw7iKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(24, input_shape=(8,), activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(12, activation='tanh'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.summary()   # Gives a summary of the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYShU_156CCL",
        "outputId": "0a690470-ed95-4743-f6f0-b7910d288f8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 24)                216       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 20)                500       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 12)                252       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,090\n",
            "Trainable params: 1,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import optimizers\n",
        "opt = optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "M2RyYz2C8540"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(X_training, Y_training, batch_size=4, epochs=750, validation_data=(X_valid,Y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47FDoQyx-tRD",
        "outputId": "ae8e2d63-22a2-4223-ab31-4cedd1cc3f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.7495 - val_loss: 0.4966 - val_accuracy: 0.7805\n",
            "Epoch 2/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7454 - val_loss: 0.4848 - val_accuracy: 0.7724\n",
            "Epoch 3/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7658 - val_loss: 0.5015 - val_accuracy: 0.7642\n",
            "Epoch 4/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.7617 - val_loss: 0.4825 - val_accuracy: 0.7805\n",
            "Epoch 5/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7556 - val_loss: 0.4903 - val_accuracy: 0.7805\n",
            "Epoch 6/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7882 - val_loss: 0.5297 - val_accuracy: 0.7154\n",
            "Epoch 7/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7617 - val_loss: 0.4666 - val_accuracy: 0.7805\n",
            "Epoch 8/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7597 - val_loss: 0.4804 - val_accuracy: 0.8049\n",
            "Epoch 9/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7597 - val_loss: 0.4754 - val_accuracy: 0.8049\n",
            "Epoch 10/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7678 - val_loss: 0.5278 - val_accuracy: 0.7561\n",
            "Epoch 11/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7536 - val_loss: 0.4674 - val_accuracy: 0.8130\n",
            "Epoch 12/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7699 - val_loss: 0.4628 - val_accuracy: 0.7967\n",
            "Epoch 13/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7739 - val_loss: 0.4747 - val_accuracy: 0.8049\n",
            "Epoch 14/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7637 - val_loss: 0.4589 - val_accuracy: 0.8049\n",
            "Epoch 15/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7739 - val_loss: 0.4912 - val_accuracy: 0.8049\n",
            "Epoch 16/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7576 - val_loss: 0.4592 - val_accuracy: 0.8211\n",
            "Epoch 17/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7597 - val_loss: 0.4581 - val_accuracy: 0.8211\n",
            "Epoch 18/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7617 - val_loss: 0.4682 - val_accuracy: 0.7724\n",
            "Epoch 19/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7658 - val_loss: 0.5029 - val_accuracy: 0.8130\n",
            "Epoch 20/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7678 - val_loss: 0.5461 - val_accuracy: 0.6829\n",
            "Epoch 21/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7658 - val_loss: 0.4746 - val_accuracy: 0.7967\n",
            "Epoch 22/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7658 - val_loss: 0.4603 - val_accuracy: 0.8049\n",
            "Epoch 23/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7597 - val_loss: 0.4678 - val_accuracy: 0.8211\n",
            "Epoch 24/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7739 - val_loss: 0.4624 - val_accuracy: 0.7967\n",
            "Epoch 25/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7658 - val_loss: 0.4566 - val_accuracy: 0.8130\n",
            "Epoch 26/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7862 - val_loss: 0.4581 - val_accuracy: 0.8049\n",
            "Epoch 27/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7637 - val_loss: 0.5278 - val_accuracy: 0.7886\n",
            "Epoch 28/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7739 - val_loss: 0.4657 - val_accuracy: 0.7886\n",
            "Epoch 29/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7739 - val_loss: 0.4552 - val_accuracy: 0.7967\n",
            "Epoch 30/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7780 - val_loss: 0.5914 - val_accuracy: 0.7317\n",
            "Epoch 31/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7739 - val_loss: 0.4590 - val_accuracy: 0.8374\n",
            "Epoch 32/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7780 - val_loss: 0.4569 - val_accuracy: 0.8049\n",
            "Epoch 33/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7637 - val_loss: 0.4836 - val_accuracy: 0.7642\n",
            "Epoch 34/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7597 - val_loss: 0.4626 - val_accuracy: 0.8211\n",
            "Epoch 35/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7780 - val_loss: 0.4582 - val_accuracy: 0.7967\n",
            "Epoch 36/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7637 - val_loss: 0.4642 - val_accuracy: 0.7886\n",
            "Epoch 37/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7576 - val_loss: 0.4843 - val_accuracy: 0.8049\n",
            "Epoch 38/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7556 - val_loss: 0.4931 - val_accuracy: 0.7724\n",
            "Epoch 39/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7637 - val_loss: 0.4591 - val_accuracy: 0.8374\n",
            "Epoch 40/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7658 - val_loss: 0.4527 - val_accuracy: 0.8049\n",
            "Epoch 41/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7780 - val_loss: 0.4602 - val_accuracy: 0.8211\n",
            "Epoch 42/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7699 - val_loss: 0.4660 - val_accuracy: 0.7886\n",
            "Epoch 43/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7597 - val_loss: 0.4780 - val_accuracy: 0.8049\n",
            "Epoch 44/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7699 - val_loss: 0.4565 - val_accuracy: 0.8211\n",
            "Epoch 45/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7699 - val_loss: 0.5176 - val_accuracy: 0.7642\n",
            "Epoch 46/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7719 - val_loss: 0.4522 - val_accuracy: 0.8211\n",
            "Epoch 47/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7637 - val_loss: 0.4656 - val_accuracy: 0.8130\n",
            "Epoch 48/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7637 - val_loss: 0.4633 - val_accuracy: 0.7967\n",
            "Epoch 49/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7719 - val_loss: 0.4559 - val_accuracy: 0.8130\n",
            "Epoch 50/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7760 - val_loss: 0.4704 - val_accuracy: 0.7886\n",
            "Epoch 51/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7617 - val_loss: 0.4921 - val_accuracy: 0.8130\n",
            "Epoch 52/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7719 - val_loss: 0.4613 - val_accuracy: 0.8049\n",
            "Epoch 53/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7658 - val_loss: 0.4549 - val_accuracy: 0.8130\n",
            "Epoch 54/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7597 - val_loss: 0.4598 - val_accuracy: 0.8049\n",
            "Epoch 55/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7658 - val_loss: 0.4581 - val_accuracy: 0.8211\n",
            "Epoch 56/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7536 - val_loss: 0.4840 - val_accuracy: 0.7967\n",
            "Epoch 57/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7637 - val_loss: 0.4644 - val_accuracy: 0.7967\n",
            "Epoch 58/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7719 - val_loss: 0.4672 - val_accuracy: 0.7886\n",
            "Epoch 59/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7719 - val_loss: 0.4584 - val_accuracy: 0.8211\n",
            "Epoch 60/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7536 - val_loss: 0.4632 - val_accuracy: 0.7886\n",
            "Epoch 61/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7699 - val_loss: 0.4573 - val_accuracy: 0.8293\n",
            "Epoch 62/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7821 - val_loss: 0.4585 - val_accuracy: 0.8211\n",
            "Epoch 63/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7862 - val_loss: 0.4758 - val_accuracy: 0.7886\n",
            "Epoch 64/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7719 - val_loss: 0.4618 - val_accuracy: 0.8130\n",
            "Epoch 65/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7780 - val_loss: 0.4657 - val_accuracy: 0.8049\n",
            "Epoch 66/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7678 - val_loss: 0.4825 - val_accuracy: 0.7886\n",
            "Epoch 67/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7597 - val_loss: 0.4674 - val_accuracy: 0.7805\n",
            "Epoch 68/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7678 - val_loss: 0.5135 - val_accuracy: 0.7967\n",
            "Epoch 69/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7902 - val_loss: 0.4776 - val_accuracy: 0.7886\n",
            "Epoch 70/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7780 - val_loss: 0.4698 - val_accuracy: 0.7805\n",
            "Epoch 71/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7658 - val_loss: 0.5405 - val_accuracy: 0.7561\n",
            "Epoch 72/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7699 - val_loss: 0.4985 - val_accuracy: 0.8130\n",
            "Epoch 73/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7678 - val_loss: 0.5099 - val_accuracy: 0.7886\n",
            "Epoch 74/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7699 - val_loss: 0.4604 - val_accuracy: 0.8130\n",
            "Epoch 75/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7800 - val_loss: 0.5177 - val_accuracy: 0.8130\n",
            "Epoch 76/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7515 - val_loss: 0.4779 - val_accuracy: 0.7886\n",
            "Epoch 77/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7699 - val_loss: 0.4735 - val_accuracy: 0.7805\n",
            "Epoch 78/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7536 - val_loss: 0.4632 - val_accuracy: 0.7886\n",
            "Epoch 79/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7699 - val_loss: 0.4674 - val_accuracy: 0.8049\n",
            "Epoch 80/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7760 - val_loss: 0.4533 - val_accuracy: 0.8130\n",
            "Epoch 81/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7556 - val_loss: 0.4950 - val_accuracy: 0.7642\n",
            "Epoch 82/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7699 - val_loss: 0.4624 - val_accuracy: 0.8130\n",
            "Epoch 83/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7637 - val_loss: 0.4552 - val_accuracy: 0.8293\n",
            "Epoch 84/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7617 - val_loss: 0.4636 - val_accuracy: 0.8130\n",
            "Epoch 85/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.7719 - val_loss: 0.4728 - val_accuracy: 0.7805\n",
            "Epoch 86/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7719 - val_loss: 0.5010 - val_accuracy: 0.7561\n",
            "Epoch 87/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7739 - val_loss: 0.4734 - val_accuracy: 0.7967\n",
            "Epoch 88/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7821 - val_loss: 0.4813 - val_accuracy: 0.7967\n",
            "Epoch 89/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7658 - val_loss: 0.4571 - val_accuracy: 0.8293\n",
            "Epoch 90/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7556 - val_loss: 0.4783 - val_accuracy: 0.7642\n",
            "Epoch 91/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7699 - val_loss: 0.4763 - val_accuracy: 0.7886\n",
            "Epoch 92/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7923 - val_loss: 0.4865 - val_accuracy: 0.7967\n",
            "Epoch 93/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7862 - val_loss: 0.4788 - val_accuracy: 0.7724\n",
            "Epoch 94/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7862 - val_loss: 0.4733 - val_accuracy: 0.7886\n",
            "Epoch 95/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7760 - val_loss: 0.4604 - val_accuracy: 0.7967\n",
            "Epoch 96/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7719 - val_loss: 0.4610 - val_accuracy: 0.7967\n",
            "Epoch 97/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7475 - val_loss: 0.5088 - val_accuracy: 0.8049\n",
            "Epoch 98/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7800 - val_loss: 0.5183 - val_accuracy: 0.8049\n",
            "Epoch 99/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7739 - val_loss: 0.4698 - val_accuracy: 0.8049\n",
            "Epoch 100/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7780 - val_loss: 0.5148 - val_accuracy: 0.7480\n",
            "Epoch 101/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7923 - val_loss: 0.4679 - val_accuracy: 0.7724\n",
            "Epoch 102/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7923 - val_loss: 0.4606 - val_accuracy: 0.7967\n",
            "Epoch 103/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7902 - val_loss: 0.5812 - val_accuracy: 0.7236\n",
            "Epoch 104/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7719 - val_loss: 0.4722 - val_accuracy: 0.7805\n",
            "Epoch 105/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7678 - val_loss: 0.4894 - val_accuracy: 0.7642\n",
            "Epoch 106/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.7923 - val_loss: 0.5231 - val_accuracy: 0.7561\n",
            "Epoch 107/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7699 - val_loss: 0.4954 - val_accuracy: 0.7642\n",
            "Epoch 108/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7800 - val_loss: 0.5258 - val_accuracy: 0.7805\n",
            "Epoch 109/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7923 - val_loss: 0.4978 - val_accuracy: 0.7967\n",
            "Epoch 110/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7800 - val_loss: 0.4827 - val_accuracy: 0.7886\n",
            "Epoch 111/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7780 - val_loss: 0.5102 - val_accuracy: 0.7967\n",
            "Epoch 112/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7760 - val_loss: 0.4894 - val_accuracy: 0.7805\n",
            "Epoch 113/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.7780 - val_loss: 0.4726 - val_accuracy: 0.7967\n",
            "Epoch 114/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7760 - val_loss: 0.5093 - val_accuracy: 0.8049\n",
            "Epoch 115/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7923 - val_loss: 0.4787 - val_accuracy: 0.7967\n",
            "Epoch 116/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7699 - val_loss: 0.5016 - val_accuracy: 0.7886\n",
            "Epoch 117/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7719 - val_loss: 0.4955 - val_accuracy: 0.7561\n",
            "Epoch 118/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7760 - val_loss: 0.4723 - val_accuracy: 0.7967\n",
            "Epoch 119/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7780 - val_loss: 0.5225 - val_accuracy: 0.8049\n",
            "Epoch 120/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7800 - val_loss: 0.5005 - val_accuracy: 0.7642\n",
            "Epoch 121/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7719 - val_loss: 0.5024 - val_accuracy: 0.7642\n",
            "Epoch 122/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7841 - val_loss: 0.4793 - val_accuracy: 0.7805\n",
            "Epoch 123/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7739 - val_loss: 0.4918 - val_accuracy: 0.7967\n",
            "Epoch 124/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7800 - val_loss: 0.4651 - val_accuracy: 0.8049\n",
            "Epoch 125/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7658 - val_loss: 0.5045 - val_accuracy: 0.7561\n",
            "Epoch 126/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7882 - val_loss: 0.4751 - val_accuracy: 0.7886\n",
            "Epoch 127/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7862 - val_loss: 0.4666 - val_accuracy: 0.7886\n",
            "Epoch 128/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7637 - val_loss: 0.4739 - val_accuracy: 0.7724\n",
            "Epoch 129/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7841 - val_loss: 0.4795 - val_accuracy: 0.7805\n",
            "Epoch 130/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.7841 - val_loss: 0.4776 - val_accuracy: 0.7805\n",
            "Epoch 131/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7862 - val_loss: 0.4872 - val_accuracy: 0.7724\n",
            "Epoch 132/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7800 - val_loss: 0.5041 - val_accuracy: 0.7642\n",
            "Epoch 133/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7719 - val_loss: 0.4998 - val_accuracy: 0.7480\n",
            "Epoch 134/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7902 - val_loss: 0.5250 - val_accuracy: 0.7805\n",
            "Epoch 135/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7760 - val_loss: 0.4852 - val_accuracy: 0.7967\n",
            "Epoch 136/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7862 - val_loss: 0.5045 - val_accuracy: 0.7886\n",
            "Epoch 137/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.7780 - val_loss: 0.4894 - val_accuracy: 0.7967\n",
            "Epoch 138/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7821 - val_loss: 0.4922 - val_accuracy: 0.7561\n",
            "Epoch 139/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.7862 - val_loss: 0.5522 - val_accuracy: 0.7886\n",
            "Epoch 140/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7800 - val_loss: 0.4717 - val_accuracy: 0.7805\n",
            "Epoch 141/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.7923 - val_loss: 0.5191 - val_accuracy: 0.7805\n",
            "Epoch 142/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.7943 - val_loss: 0.5376 - val_accuracy: 0.7724\n",
            "Epoch 143/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7943 - val_loss: 0.5299 - val_accuracy: 0.7967\n",
            "Epoch 144/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8106 - val_loss: 0.5179 - val_accuracy: 0.7642\n",
            "Epoch 145/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7800 - val_loss: 0.5227 - val_accuracy: 0.7642\n",
            "Epoch 146/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4135 - accuracy: 0.7841 - val_loss: 0.4903 - val_accuracy: 0.7805\n",
            "Epoch 147/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.7882 - val_loss: 0.5056 - val_accuracy: 0.7561\n",
            "Epoch 148/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7821 - val_loss: 0.4864 - val_accuracy: 0.7805\n",
            "Epoch 149/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.7943 - val_loss: 0.5324 - val_accuracy: 0.7724\n",
            "Epoch 150/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8065 - val_loss: 0.5612 - val_accuracy: 0.7805\n",
            "Epoch 151/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8024 - val_loss: 0.5030 - val_accuracy: 0.7886\n",
            "Epoch 152/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.7780 - val_loss: 0.4966 - val_accuracy: 0.7642\n",
            "Epoch 153/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.7800 - val_loss: 0.5136 - val_accuracy: 0.7886\n",
            "Epoch 154/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3934 - accuracy: 0.8086 - val_loss: 0.5884 - val_accuracy: 0.7805\n",
            "Epoch 155/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8045 - val_loss: 0.5312 - val_accuracy: 0.7724\n",
            "Epoch 156/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.7943 - val_loss: 0.5095 - val_accuracy: 0.7642\n",
            "Epoch 157/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.7923 - val_loss: 0.4791 - val_accuracy: 0.8130\n",
            "Epoch 158/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8004 - val_loss: 0.4759 - val_accuracy: 0.7886\n",
            "Epoch 159/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.7943 - val_loss: 0.5171 - val_accuracy: 0.7642\n",
            "Epoch 160/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.7963 - val_loss: 0.5310 - val_accuracy: 0.7724\n",
            "Epoch 161/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4000 - accuracy: 0.8065 - val_loss: 0.5052 - val_accuracy: 0.7724\n",
            "Epoch 162/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.7943 - val_loss: 0.4952 - val_accuracy: 0.7724\n",
            "Epoch 163/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8126 - val_loss: 0.4927 - val_accuracy: 0.8049\n",
            "Epoch 164/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8086 - val_loss: 0.4898 - val_accuracy: 0.7886\n",
            "Epoch 165/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8106 - val_loss: 0.4849 - val_accuracy: 0.7967\n",
            "Epoch 166/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8208 - val_loss: 0.4791 - val_accuracy: 0.7886\n",
            "Epoch 167/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.7963 - val_loss: 0.5139 - val_accuracy: 0.7480\n",
            "Epoch 168/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4050 - accuracy: 0.8106 - val_loss: 0.5078 - val_accuracy: 0.7886\n",
            "Epoch 169/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8024 - val_loss: 0.4852 - val_accuracy: 0.7805\n",
            "Epoch 170/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8004 - val_loss: 0.5200 - val_accuracy: 0.7805\n",
            "Epoch 171/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8167 - val_loss: 0.5128 - val_accuracy: 0.7724\n",
            "Epoch 172/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8106 - val_loss: 0.4915 - val_accuracy: 0.7561\n",
            "Epoch 173/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8045 - val_loss: 0.5238 - val_accuracy: 0.7724\n",
            "Epoch 174/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8045 - val_loss: 0.5154 - val_accuracy: 0.7724\n",
            "Epoch 175/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8167 - val_loss: 0.5117 - val_accuracy: 0.7805\n",
            "Epoch 176/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3855 - accuracy: 0.8045 - val_loss: 0.5040 - val_accuracy: 0.7642\n",
            "Epoch 177/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3957 - accuracy: 0.8045 - val_loss: 0.5078 - val_accuracy: 0.7886\n",
            "Epoch 178/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3976 - accuracy: 0.8004 - val_loss: 0.6266 - val_accuracy: 0.7642\n",
            "Epoch 179/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8147 - val_loss: 0.5408 - val_accuracy: 0.7805\n",
            "Epoch 180/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8024 - val_loss: 0.5282 - val_accuracy: 0.7642\n",
            "Epoch 181/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8167 - val_loss: 0.5017 - val_accuracy: 0.7724\n",
            "Epoch 182/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8065 - val_loss: 0.4804 - val_accuracy: 0.8049\n",
            "Epoch 183/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.8147 - val_loss: 0.5587 - val_accuracy: 0.7724\n",
            "Epoch 184/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8126 - val_loss: 0.5206 - val_accuracy: 0.7642\n",
            "Epoch 185/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8065 - val_loss: 0.5099 - val_accuracy: 0.7805\n",
            "Epoch 186/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8147 - val_loss: 0.4947 - val_accuracy: 0.8049\n",
            "Epoch 187/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8126 - val_loss: 0.4946 - val_accuracy: 0.7805\n",
            "Epoch 188/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8106 - val_loss: 0.5179 - val_accuracy: 0.7642\n",
            "Epoch 189/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8065 - val_loss: 0.5669 - val_accuracy: 0.7642\n",
            "Epoch 190/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8147 - val_loss: 0.5658 - val_accuracy: 0.7724\n",
            "Epoch 191/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8086 - val_loss: 0.6137 - val_accuracy: 0.7561\n",
            "Epoch 192/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.8004 - val_loss: 0.5156 - val_accuracy: 0.7642\n",
            "Epoch 193/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8024 - val_loss: 0.5130 - val_accuracy: 0.7724\n",
            "Epoch 194/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8289 - val_loss: 0.5356 - val_accuracy: 0.7724\n",
            "Epoch 195/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8248 - val_loss: 0.5000 - val_accuracy: 0.7886\n",
            "Epoch 196/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3869 - accuracy: 0.8187 - val_loss: 0.5002 - val_accuracy: 0.7724\n",
            "Epoch 197/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8086 - val_loss: 0.5500 - val_accuracy: 0.7805\n",
            "Epoch 198/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3863 - accuracy: 0.8147 - val_loss: 0.5413 - val_accuracy: 0.7398\n",
            "Epoch 199/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8065 - val_loss: 0.6128 - val_accuracy: 0.7561\n",
            "Epoch 200/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8187 - val_loss: 0.5135 - val_accuracy: 0.8049\n",
            "Epoch 201/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8167 - val_loss: 0.5254 - val_accuracy: 0.7805\n",
            "Epoch 202/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8187 - val_loss: 0.5601 - val_accuracy: 0.7642\n",
            "Epoch 203/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8289 - val_loss: 0.5621 - val_accuracy: 0.7561\n",
            "Epoch 204/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8310 - val_loss: 0.5154 - val_accuracy: 0.7724\n",
            "Epoch 205/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8289 - val_loss: 0.5219 - val_accuracy: 0.7480\n",
            "Epoch 206/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8086 - val_loss: 0.5177 - val_accuracy: 0.7561\n",
            "Epoch 207/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3835 - accuracy: 0.8208 - val_loss: 0.5584 - val_accuracy: 0.7724\n",
            "Epoch 208/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.8086 - val_loss: 0.5271 - val_accuracy: 0.7642\n",
            "Epoch 209/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.8248 - val_loss: 0.5682 - val_accuracy: 0.7480\n",
            "Epoch 210/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8126 - val_loss: 0.5142 - val_accuracy: 0.7805\n",
            "Epoch 211/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3751 - accuracy: 0.8208 - val_loss: 0.5243 - val_accuracy: 0.7642\n",
            "Epoch 212/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3734 - accuracy: 0.8289 - val_loss: 0.5012 - val_accuracy: 0.7967\n",
            "Epoch 213/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8228 - val_loss: 0.5376 - val_accuracy: 0.7724\n",
            "Epoch 214/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8248 - val_loss: 0.5572 - val_accuracy: 0.7480\n",
            "Epoch 215/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3784 - accuracy: 0.8371 - val_loss: 0.5298 - val_accuracy: 0.7561\n",
            "Epoch 216/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3728 - accuracy: 0.8269 - val_loss: 0.5000 - val_accuracy: 0.7724\n",
            "Epoch 217/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8187 - val_loss: 0.5917 - val_accuracy: 0.7561\n",
            "Epoch 218/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3864 - accuracy: 0.8086 - val_loss: 0.5664 - val_accuracy: 0.7561\n",
            "Epoch 219/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8167 - val_loss: 0.5119 - val_accuracy: 0.7480\n",
            "Epoch 220/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8269 - val_loss: 0.6446 - val_accuracy: 0.7480\n",
            "Epoch 221/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3784 - accuracy: 0.8167 - val_loss: 0.5121 - val_accuracy: 0.7805\n",
            "Epoch 222/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8065 - val_loss: 0.5375 - val_accuracy: 0.7561\n",
            "Epoch 223/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3791 - accuracy: 0.8208 - val_loss: 0.5841 - val_accuracy: 0.7154\n",
            "Epoch 224/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3714 - accuracy: 0.8248 - val_loss: 0.4962 - val_accuracy: 0.7642\n",
            "Epoch 225/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3716 - accuracy: 0.8208 - val_loss: 0.5395 - val_accuracy: 0.7642\n",
            "Epoch 226/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3836 - accuracy: 0.8228 - val_loss: 0.5252 - val_accuracy: 0.7805\n",
            "Epoch 227/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3689 - accuracy: 0.8371 - val_loss: 0.7138 - val_accuracy: 0.6585\n",
            "Epoch 228/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3697 - accuracy: 0.8289 - val_loss: 0.5362 - val_accuracy: 0.7886\n",
            "Epoch 229/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8126 - val_loss: 0.5424 - val_accuracy: 0.7724\n",
            "Epoch 230/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3782 - accuracy: 0.8269 - val_loss: 0.5039 - val_accuracy: 0.7561\n",
            "Epoch 231/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8187 - val_loss: 0.5241 - val_accuracy: 0.7561\n",
            "Epoch 232/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8106 - val_loss: 0.5750 - val_accuracy: 0.7480\n",
            "Epoch 233/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8289 - val_loss: 0.5160 - val_accuracy: 0.7561\n",
            "Epoch 234/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8371 - val_loss: 0.5899 - val_accuracy: 0.7642\n",
            "Epoch 235/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3605 - accuracy: 0.8411 - val_loss: 0.5722 - val_accuracy: 0.7398\n",
            "Epoch 236/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8289 - val_loss: 0.5545 - val_accuracy: 0.7642\n",
            "Epoch 237/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8228 - val_loss: 0.5361 - val_accuracy: 0.7398\n",
            "Epoch 238/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3749 - accuracy: 0.8310 - val_loss: 0.5215 - val_accuracy: 0.7724\n",
            "Epoch 239/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3617 - accuracy: 0.8473 - val_loss: 0.5898 - val_accuracy: 0.7724\n",
            "Epoch 240/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8228 - val_loss: 0.5827 - val_accuracy: 0.7642\n",
            "Epoch 241/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.8208 - val_loss: 0.5616 - val_accuracy: 0.7642\n",
            "Epoch 242/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3643 - accuracy: 0.8330 - val_loss: 0.6465 - val_accuracy: 0.7317\n",
            "Epoch 243/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3681 - accuracy: 0.8289 - val_loss: 0.5509 - val_accuracy: 0.7724\n",
            "Epoch 244/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8391 - val_loss: 0.5434 - val_accuracy: 0.7561\n",
            "Epoch 245/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8371 - val_loss: 0.5138 - val_accuracy: 0.7724\n",
            "Epoch 246/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8330 - val_loss: 0.5184 - val_accuracy: 0.7642\n",
            "Epoch 247/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8208 - val_loss: 0.5468 - val_accuracy: 0.7724\n",
            "Epoch 248/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3596 - accuracy: 0.8289 - val_loss: 0.5634 - val_accuracy: 0.7805\n",
            "Epoch 249/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3590 - accuracy: 0.8391 - val_loss: 0.5898 - val_accuracy: 0.7642\n",
            "Epoch 250/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8391 - val_loss: 0.5264 - val_accuracy: 0.8049\n",
            "Epoch 251/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8289 - val_loss: 0.5733 - val_accuracy: 0.7236\n",
            "Epoch 252/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8350 - val_loss: 0.5588 - val_accuracy: 0.7398\n",
            "Epoch 253/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8289 - val_loss: 0.5502 - val_accuracy: 0.7561\n",
            "Epoch 254/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8391 - val_loss: 0.5754 - val_accuracy: 0.6829\n",
            "Epoch 255/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8269 - val_loss: 0.5697 - val_accuracy: 0.7805\n",
            "Epoch 256/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8391 - val_loss: 0.5903 - val_accuracy: 0.7561\n",
            "Epoch 257/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.8248 - val_loss: 0.5370 - val_accuracy: 0.7642\n",
            "Epoch 258/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8452 - val_loss: 0.5361 - val_accuracy: 0.7805\n",
            "Epoch 259/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8248 - val_loss: 0.5461 - val_accuracy: 0.7642\n",
            "Epoch 260/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3499 - accuracy: 0.8432 - val_loss: 0.5999 - val_accuracy: 0.7642\n",
            "Epoch 261/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8411 - val_loss: 0.5699 - val_accuracy: 0.7480\n",
            "Epoch 262/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3598 - accuracy: 0.8330 - val_loss: 0.6101 - val_accuracy: 0.7480\n",
            "Epoch 263/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3585 - accuracy: 0.8371 - val_loss: 0.5464 - val_accuracy: 0.7642\n",
            "Epoch 264/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8432 - val_loss: 0.5103 - val_accuracy: 0.8130\n",
            "Epoch 265/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8493 - val_loss: 0.6084 - val_accuracy: 0.7724\n",
            "Epoch 266/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8289 - val_loss: 0.5142 - val_accuracy: 0.7642\n",
            "Epoch 267/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8289 - val_loss: 0.5527 - val_accuracy: 0.7724\n",
            "Epoch 268/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8330 - val_loss: 0.7241 - val_accuracy: 0.7398\n",
            "Epoch 269/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8310 - val_loss: 0.5411 - val_accuracy: 0.7642\n",
            "Epoch 270/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8452 - val_loss: 0.5240 - val_accuracy: 0.7967\n",
            "Epoch 271/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.8554 - val_loss: 0.5642 - val_accuracy: 0.7724\n",
            "Epoch 272/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3516 - accuracy: 0.8371 - val_loss: 0.5685 - val_accuracy: 0.7561\n",
            "Epoch 273/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3566 - accuracy: 0.8371 - val_loss: 0.5541 - val_accuracy: 0.7642\n",
            "Epoch 274/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8411 - val_loss: 0.5544 - val_accuracy: 0.7886\n",
            "Epoch 275/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3596 - accuracy: 0.8310 - val_loss: 0.5258 - val_accuracy: 0.7886\n",
            "Epoch 276/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3561 - accuracy: 0.8452 - val_loss: 0.5426 - val_accuracy: 0.7886\n",
            "Epoch 277/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8350 - val_loss: 0.5259 - val_accuracy: 0.7724\n",
            "Epoch 278/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3550 - accuracy: 0.8432 - val_loss: 0.5796 - val_accuracy: 0.7642\n",
            "Epoch 279/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8432 - val_loss: 0.5619 - val_accuracy: 0.7480\n",
            "Epoch 280/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3424 - accuracy: 0.8493 - val_loss: 0.5575 - val_accuracy: 0.7480\n",
            "Epoch 281/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8473 - val_loss: 0.5722 - val_accuracy: 0.7805\n",
            "Epoch 282/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3505 - accuracy: 0.8330 - val_loss: 0.5250 - val_accuracy: 0.7805\n",
            "Epoch 283/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8391 - val_loss: 0.5600 - val_accuracy: 0.7805\n",
            "Epoch 284/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8248 - val_loss: 0.5552 - val_accuracy: 0.7073\n",
            "Epoch 285/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3575 - accuracy: 0.8493 - val_loss: 0.5262 - val_accuracy: 0.7805\n",
            "Epoch 286/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8513 - val_loss: 0.5261 - val_accuracy: 0.7967\n",
            "Epoch 287/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3459 - accuracy: 0.8595 - val_loss: 0.5528 - val_accuracy: 0.7724\n",
            "Epoch 288/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3506 - accuracy: 0.8595 - val_loss: 0.5127 - val_accuracy: 0.7967\n",
            "Epoch 289/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3378 - accuracy: 0.8371 - val_loss: 0.4917 - val_accuracy: 0.7805\n",
            "Epoch 290/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3463 - accuracy: 0.8411 - val_loss: 0.5726 - val_accuracy: 0.6911\n",
            "Epoch 291/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3487 - accuracy: 0.8350 - val_loss: 0.5931 - val_accuracy: 0.7480\n",
            "Epoch 292/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3464 - accuracy: 0.8493 - val_loss: 0.5995 - val_accuracy: 0.7480\n",
            "Epoch 293/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8452 - val_loss: 0.5877 - val_accuracy: 0.7398\n",
            "Epoch 294/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8473 - val_loss: 0.5623 - val_accuracy: 0.7236\n",
            "Epoch 295/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8534 - val_loss: 0.5612 - val_accuracy: 0.7642\n",
            "Epoch 296/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.8391 - val_loss: 0.5392 - val_accuracy: 0.7724\n",
            "Epoch 297/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3467 - accuracy: 0.8452 - val_loss: 0.5880 - val_accuracy: 0.7154\n",
            "Epoch 298/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3448 - accuracy: 0.8554 - val_loss: 0.5745 - val_accuracy: 0.7642\n",
            "Epoch 299/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8391 - val_loss: 0.5830 - val_accuracy: 0.7561\n",
            "Epoch 300/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3466 - accuracy: 0.8676 - val_loss: 0.5308 - val_accuracy: 0.8049\n",
            "Epoch 301/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8350 - val_loss: 0.5976 - val_accuracy: 0.7073\n",
            "Epoch 302/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8473 - val_loss: 0.5570 - val_accuracy: 0.7561\n",
            "Epoch 303/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8248 - val_loss: 0.5786 - val_accuracy: 0.7561\n",
            "Epoch 304/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8595 - val_loss: 0.5498 - val_accuracy: 0.7724\n",
            "Epoch 305/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8391 - val_loss: 0.5717 - val_accuracy: 0.7480\n",
            "Epoch 306/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8493 - val_loss: 0.5442 - val_accuracy: 0.7805\n",
            "Epoch 307/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3456 - accuracy: 0.8391 - val_loss: 0.5302 - val_accuracy: 0.7724\n",
            "Epoch 308/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3439 - accuracy: 0.8635 - val_loss: 0.5311 - val_accuracy: 0.7805\n",
            "Epoch 309/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8554 - val_loss: 0.5749 - val_accuracy: 0.7561\n",
            "Epoch 310/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8595 - val_loss: 0.5912 - val_accuracy: 0.7724\n",
            "Epoch 311/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8350 - val_loss: 0.5552 - val_accuracy: 0.7724\n",
            "Epoch 312/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8574 - val_loss: 0.5680 - val_accuracy: 0.7480\n",
            "Epoch 313/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8595 - val_loss: 0.5483 - val_accuracy: 0.7317\n",
            "Epoch 314/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3391 - accuracy: 0.8554 - val_loss: 0.5745 - val_accuracy: 0.7724\n",
            "Epoch 315/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3438 - accuracy: 0.8411 - val_loss: 0.5330 - val_accuracy: 0.7724\n",
            "Epoch 316/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3414 - accuracy: 0.8574 - val_loss: 0.5952 - val_accuracy: 0.7480\n",
            "Epoch 317/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8452 - val_loss: 0.6277 - val_accuracy: 0.6992\n",
            "Epoch 318/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8473 - val_loss: 0.6062 - val_accuracy: 0.7317\n",
            "Epoch 319/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8534 - val_loss: 0.5564 - val_accuracy: 0.7886\n",
            "Epoch 320/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8554 - val_loss: 0.6688 - val_accuracy: 0.7317\n",
            "Epoch 321/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3460 - accuracy: 0.8452 - val_loss: 0.6238 - val_accuracy: 0.7561\n",
            "Epoch 322/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8411 - val_loss: 0.5480 - val_accuracy: 0.7561\n",
            "Epoch 323/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8574 - val_loss: 0.6109 - val_accuracy: 0.7317\n",
            "Epoch 324/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3392 - accuracy: 0.8554 - val_loss: 0.5313 - val_accuracy: 0.7642\n",
            "Epoch 325/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.8452 - val_loss: 0.5749 - val_accuracy: 0.7480\n",
            "Epoch 326/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8676 - val_loss: 0.6030 - val_accuracy: 0.7480\n",
            "Epoch 327/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8615 - val_loss: 0.6193 - val_accuracy: 0.7561\n",
            "Epoch 328/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8554 - val_loss: 0.5431 - val_accuracy: 0.7724\n",
            "Epoch 329/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8534 - val_loss: 0.5977 - val_accuracy: 0.7561\n",
            "Epoch 330/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3311 - accuracy: 0.8534 - val_loss: 0.5300 - val_accuracy: 0.7642\n",
            "Epoch 331/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8473 - val_loss: 0.6271 - val_accuracy: 0.7805\n",
            "Epoch 332/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3262 - accuracy: 0.8656 - val_loss: 0.5722 - val_accuracy: 0.7317\n",
            "Epoch 333/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.8493 - val_loss: 0.5774 - val_accuracy: 0.7480\n",
            "Epoch 334/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.8574 - val_loss: 0.5548 - val_accuracy: 0.7886\n",
            "Epoch 335/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8534 - val_loss: 0.6254 - val_accuracy: 0.7642\n",
            "Epoch 336/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3271 - accuracy: 0.8452 - val_loss: 0.5686 - val_accuracy: 0.7561\n",
            "Epoch 337/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3321 - accuracy: 0.8615 - val_loss: 0.6056 - val_accuracy: 0.7317\n",
            "Epoch 338/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.8554 - val_loss: 0.6346 - val_accuracy: 0.7317\n",
            "Epoch 339/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8452 - val_loss: 0.5753 - val_accuracy: 0.7642\n",
            "Epoch 340/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8493 - val_loss: 0.5970 - val_accuracy: 0.7642\n",
            "Epoch 341/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3192 - accuracy: 0.8676 - val_loss: 0.6543 - val_accuracy: 0.7642\n",
            "Epoch 342/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3162 - accuracy: 0.8737 - val_loss: 0.6069 - val_accuracy: 0.7154\n",
            "Epoch 343/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3147 - accuracy: 0.8676 - val_loss: 0.6587 - val_accuracy: 0.7073\n",
            "Epoch 344/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3264 - accuracy: 0.8513 - val_loss: 0.5817 - val_accuracy: 0.7724\n",
            "Epoch 345/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8493 - val_loss: 0.5596 - val_accuracy: 0.7724\n",
            "Epoch 346/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3162 - accuracy: 0.8656 - val_loss: 0.6211 - val_accuracy: 0.6911\n",
            "Epoch 347/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3366 - accuracy: 0.8534 - val_loss: 0.6241 - val_accuracy: 0.7317\n",
            "Epoch 348/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3271 - accuracy: 0.8554 - val_loss: 0.5533 - val_accuracy: 0.7480\n",
            "Epoch 349/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3306 - accuracy: 0.8513 - val_loss: 0.5951 - val_accuracy: 0.7317\n",
            "Epoch 350/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3226 - accuracy: 0.8432 - val_loss: 0.5940 - val_accuracy: 0.7398\n",
            "Epoch 351/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8615 - val_loss: 0.5965 - val_accuracy: 0.7642\n",
            "Epoch 352/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3193 - accuracy: 0.8452 - val_loss: 0.6745 - val_accuracy: 0.7398\n",
            "Epoch 353/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8574 - val_loss: 0.5576 - val_accuracy: 0.7398\n",
            "Epoch 354/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8513 - val_loss: 0.5673 - val_accuracy: 0.7480\n",
            "Epoch 355/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8676 - val_loss: 0.5763 - val_accuracy: 0.7642\n",
            "Epoch 356/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8676 - val_loss: 0.6308 - val_accuracy: 0.7642\n",
            "Epoch 357/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2986 - accuracy: 0.8717 - val_loss: 0.7515 - val_accuracy: 0.6748\n",
            "Epoch 358/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3218 - accuracy: 0.8595 - val_loss: 0.5615 - val_accuracy: 0.7317\n",
            "Epoch 359/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8595 - val_loss: 0.6018 - val_accuracy: 0.7317\n",
            "Epoch 360/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8534 - val_loss: 0.5683 - val_accuracy: 0.7886\n",
            "Epoch 361/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3194 - accuracy: 0.8554 - val_loss: 0.6623 - val_accuracy: 0.7398\n",
            "Epoch 362/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.8473 - val_loss: 0.6045 - val_accuracy: 0.7561\n",
            "Epoch 363/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3057 - accuracy: 0.8839 - val_loss: 0.6820 - val_accuracy: 0.7317\n",
            "Epoch 364/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8493 - val_loss: 0.5976 - val_accuracy: 0.7236\n",
            "Epoch 365/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8574 - val_loss: 0.5669 - val_accuracy: 0.7154\n",
            "Epoch 366/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8839 - val_loss: 0.5741 - val_accuracy: 0.7724\n",
            "Epoch 367/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8615 - val_loss: 0.6604 - val_accuracy: 0.7154\n",
            "Epoch 368/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.8697 - val_loss: 0.5716 - val_accuracy: 0.7642\n",
            "Epoch 369/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8635 - val_loss: 0.5836 - val_accuracy: 0.7724\n",
            "Epoch 370/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3156 - accuracy: 0.8676 - val_loss: 0.6118 - val_accuracy: 0.7398\n",
            "Epoch 371/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3008 - accuracy: 0.8595 - val_loss: 0.6364 - val_accuracy: 0.7480\n",
            "Epoch 372/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3075 - accuracy: 0.8717 - val_loss: 0.5760 - val_accuracy: 0.7967\n",
            "Epoch 373/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3115 - accuracy: 0.8534 - val_loss: 0.6024 - val_accuracy: 0.7642\n",
            "Epoch 374/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3061 - accuracy: 0.8717 - val_loss: 0.6058 - val_accuracy: 0.7317\n",
            "Epoch 375/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8676 - val_loss: 0.5936 - val_accuracy: 0.7805\n",
            "Epoch 376/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8676 - val_loss: 0.5607 - val_accuracy: 0.7561\n",
            "Epoch 377/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.8778 - val_loss: 0.6247 - val_accuracy: 0.7561\n",
            "Epoch 378/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3058 - accuracy: 0.8615 - val_loss: 0.6092 - val_accuracy: 0.7398\n",
            "Epoch 379/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.8676 - val_loss: 0.6080 - val_accuracy: 0.7480\n",
            "Epoch 380/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3096 - accuracy: 0.8737 - val_loss: 0.5789 - val_accuracy: 0.7805\n",
            "Epoch 381/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2893 - accuracy: 0.8921 - val_loss: 0.6064 - val_accuracy: 0.7886\n",
            "Epoch 382/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3000 - accuracy: 0.8717 - val_loss: 0.6358 - val_accuracy: 0.7561\n",
            "Epoch 383/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3136 - accuracy: 0.8758 - val_loss: 0.6074 - val_accuracy: 0.7724\n",
            "Epoch 384/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2976 - accuracy: 0.8737 - val_loss: 0.6452 - val_accuracy: 0.7561\n",
            "Epoch 385/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3083 - accuracy: 0.8656 - val_loss: 0.5963 - val_accuracy: 0.7561\n",
            "Epoch 386/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3012 - accuracy: 0.8635 - val_loss: 0.5865 - val_accuracy: 0.7480\n",
            "Epoch 387/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3009 - accuracy: 0.8737 - val_loss: 0.6805 - val_accuracy: 0.7317\n",
            "Epoch 388/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3026 - accuracy: 0.8554 - val_loss: 0.6395 - val_accuracy: 0.7317\n",
            "Epoch 389/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.8737 - val_loss: 0.5930 - val_accuracy: 0.7967\n",
            "Epoch 390/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2890 - accuracy: 0.8635 - val_loss: 0.6547 - val_accuracy: 0.7398\n",
            "Epoch 391/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.8595 - val_loss: 0.6050 - val_accuracy: 0.7886\n",
            "Epoch 392/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.8697 - val_loss: 0.6395 - val_accuracy: 0.7561\n",
            "Epoch 393/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3014 - accuracy: 0.8697 - val_loss: 0.6355 - val_accuracy: 0.7724\n",
            "Epoch 394/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3037 - accuracy: 0.8554 - val_loss: 0.6631 - val_accuracy: 0.7398\n",
            "Epoch 395/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2993 - accuracy: 0.8839 - val_loss: 0.7622 - val_accuracy: 0.7480\n",
            "Epoch 396/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3036 - accuracy: 0.8676 - val_loss: 0.6294 - val_accuracy: 0.7642\n",
            "Epoch 397/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3121 - accuracy: 0.8635 - val_loss: 0.6855 - val_accuracy: 0.7724\n",
            "Epoch 398/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3016 - accuracy: 0.8595 - val_loss: 0.6262 - val_accuracy: 0.7724\n",
            "Epoch 399/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3073 - accuracy: 0.8635 - val_loss: 0.6282 - val_accuracy: 0.7886\n",
            "Epoch 400/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3052 - accuracy: 0.8656 - val_loss: 0.6507 - val_accuracy: 0.7480\n",
            "Epoch 401/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2963 - accuracy: 0.8615 - val_loss: 0.6082 - val_accuracy: 0.7480\n",
            "Epoch 402/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3089 - accuracy: 0.8615 - val_loss: 0.6419 - val_accuracy: 0.7236\n",
            "Epoch 403/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2995 - accuracy: 0.8615 - val_loss: 0.6261 - val_accuracy: 0.7236\n",
            "Epoch 404/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2888 - accuracy: 0.8758 - val_loss: 0.6109 - val_accuracy: 0.7805\n",
            "Epoch 405/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.8697 - val_loss: 0.6468 - val_accuracy: 0.7398\n",
            "Epoch 406/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2855 - accuracy: 0.8778 - val_loss: 0.6147 - val_accuracy: 0.7480\n",
            "Epoch 407/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2958 - accuracy: 0.8635 - val_loss: 0.6891 - val_accuracy: 0.7398\n",
            "Epoch 408/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2881 - accuracy: 0.8676 - val_loss: 0.6817 - val_accuracy: 0.7805\n",
            "Epoch 409/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2967 - accuracy: 0.8697 - val_loss: 0.6277 - val_accuracy: 0.7805\n",
            "Epoch 410/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2888 - accuracy: 0.8758 - val_loss: 0.6698 - val_accuracy: 0.7642\n",
            "Epoch 411/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2877 - accuracy: 0.8778 - val_loss: 0.6298 - val_accuracy: 0.7642\n",
            "Epoch 412/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2904 - accuracy: 0.8778 - val_loss: 0.6219 - val_accuracy: 0.8049\n",
            "Epoch 413/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2899 - accuracy: 0.8717 - val_loss: 0.7136 - val_accuracy: 0.7642\n",
            "Epoch 414/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.8839 - val_loss: 0.7113 - val_accuracy: 0.7154\n",
            "Epoch 415/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2913 - accuracy: 0.8778 - val_loss: 0.7419 - val_accuracy: 0.7480\n",
            "Epoch 416/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2971 - accuracy: 0.8717 - val_loss: 0.7123 - val_accuracy: 0.7480\n",
            "Epoch 417/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2820 - accuracy: 0.8859 - val_loss: 0.7131 - val_accuracy: 0.7154\n",
            "Epoch 418/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2921 - accuracy: 0.8778 - val_loss: 0.6285 - val_accuracy: 0.7886\n",
            "Epoch 419/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2882 - accuracy: 0.8778 - val_loss: 0.6491 - val_accuracy: 0.7642\n",
            "Epoch 420/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2940 - accuracy: 0.8595 - val_loss: 0.7314 - val_accuracy: 0.7480\n",
            "Epoch 421/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2910 - accuracy: 0.8778 - val_loss: 0.7000 - val_accuracy: 0.7561\n",
            "Epoch 422/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2902 - accuracy: 0.8798 - val_loss: 0.6435 - val_accuracy: 0.7724\n",
            "Epoch 423/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2769 - accuracy: 0.8758 - val_loss: 0.7186 - val_accuracy: 0.7317\n",
            "Epoch 424/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2852 - accuracy: 0.8737 - val_loss: 0.6410 - val_accuracy: 0.7967\n",
            "Epoch 425/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2770 - accuracy: 0.8798 - val_loss: 0.6582 - val_accuracy: 0.7154\n",
            "Epoch 426/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2989 - accuracy: 0.8737 - val_loss: 0.6862 - val_accuracy: 0.7236\n",
            "Epoch 427/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2910 - accuracy: 0.8635 - val_loss: 0.6732 - val_accuracy: 0.7398\n",
            "Epoch 428/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2993 - accuracy: 0.8635 - val_loss: 0.6859 - val_accuracy: 0.7236\n",
            "Epoch 429/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2749 - accuracy: 0.8880 - val_loss: 0.7284 - val_accuracy: 0.7154\n",
            "Epoch 430/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2730 - accuracy: 0.8839 - val_loss: 0.6689 - val_accuracy: 0.7724\n",
            "Epoch 431/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2784 - accuracy: 0.8697 - val_loss: 0.6806 - val_accuracy: 0.7398\n",
            "Epoch 432/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.8819 - val_loss: 0.7091 - val_accuracy: 0.7561\n",
            "Epoch 433/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2844 - accuracy: 0.8839 - val_loss: 0.6640 - val_accuracy: 0.7642\n",
            "Epoch 434/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2804 - accuracy: 0.8758 - val_loss: 0.6498 - val_accuracy: 0.7724\n",
            "Epoch 435/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.8697 - val_loss: 0.6759 - val_accuracy: 0.7724\n",
            "Epoch 436/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2766 - accuracy: 0.8819 - val_loss: 0.6388 - val_accuracy: 0.7967\n",
            "Epoch 437/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2720 - accuracy: 0.8839 - val_loss: 0.6798 - val_accuracy: 0.7561\n",
            "Epoch 438/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2731 - accuracy: 0.8758 - val_loss: 0.7234 - val_accuracy: 0.7561\n",
            "Epoch 439/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2867 - accuracy: 0.8778 - val_loss: 0.6678 - val_accuracy: 0.7886\n",
            "Epoch 440/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2747 - accuracy: 0.8737 - val_loss: 0.6630 - val_accuracy: 0.7480\n",
            "Epoch 441/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.8758 - val_loss: 0.6944 - val_accuracy: 0.7236\n",
            "Epoch 442/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2734 - accuracy: 0.8615 - val_loss: 0.7800 - val_accuracy: 0.7561\n",
            "Epoch 443/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2782 - accuracy: 0.8717 - val_loss: 0.6382 - val_accuracy: 0.7886\n",
            "Epoch 444/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2846 - accuracy: 0.8656 - val_loss: 0.6653 - val_accuracy: 0.7805\n",
            "Epoch 445/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2755 - accuracy: 0.8859 - val_loss: 0.6766 - val_accuracy: 0.7480\n",
            "Epoch 446/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2855 - accuracy: 0.8839 - val_loss: 0.6904 - val_accuracy: 0.7480\n",
            "Epoch 447/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2722 - accuracy: 0.8880 - val_loss: 0.7510 - val_accuracy: 0.7480\n",
            "Epoch 448/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2684 - accuracy: 0.8880 - val_loss: 0.6276 - val_accuracy: 0.7886\n",
            "Epoch 449/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2725 - accuracy: 0.8859 - val_loss: 0.7164 - val_accuracy: 0.7724\n",
            "Epoch 450/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2851 - accuracy: 0.8635 - val_loss: 0.6863 - val_accuracy: 0.8049\n",
            "Epoch 451/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2792 - accuracy: 0.8778 - val_loss: 0.6498 - val_accuracy: 0.7805\n",
            "Epoch 452/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2582 - accuracy: 0.8859 - val_loss: 0.7029 - val_accuracy: 0.7398\n",
            "Epoch 453/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.8982 - val_loss: 0.8588 - val_accuracy: 0.6748\n",
            "Epoch 454/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2662 - accuracy: 0.8819 - val_loss: 0.6364 - val_accuracy: 0.7967\n",
            "Epoch 455/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2687 - accuracy: 0.8941 - val_loss: 0.7184 - val_accuracy: 0.7236\n",
            "Epoch 456/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2762 - accuracy: 0.8798 - val_loss: 0.7738 - val_accuracy: 0.7398\n",
            "Epoch 457/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2683 - accuracy: 0.8798 - val_loss: 0.7176 - val_accuracy: 0.7236\n",
            "Epoch 458/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2775 - accuracy: 0.8839 - val_loss: 0.6853 - val_accuracy: 0.7480\n",
            "Epoch 459/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2727 - accuracy: 0.8778 - val_loss: 0.7245 - val_accuracy: 0.7724\n",
            "Epoch 460/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2671 - accuracy: 0.8717 - val_loss: 0.6843 - val_accuracy: 0.7805\n",
            "Epoch 461/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2727 - accuracy: 0.8676 - val_loss: 0.6925 - val_accuracy: 0.7886\n",
            "Epoch 462/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.8880 - val_loss: 0.6505 - val_accuracy: 0.7317\n",
            "Epoch 463/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.8921 - val_loss: 0.7503 - val_accuracy: 0.7317\n",
            "Epoch 464/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2840 - accuracy: 0.8839 - val_loss: 0.8118 - val_accuracy: 0.7480\n",
            "Epoch 465/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2790 - accuracy: 0.8819 - val_loss: 0.7442 - val_accuracy: 0.7642\n",
            "Epoch 466/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2640 - accuracy: 0.8839 - val_loss: 0.7902 - val_accuracy: 0.7317\n",
            "Epoch 467/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.8798 - val_loss: 0.8073 - val_accuracy: 0.7398\n",
            "Epoch 468/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2626 - accuracy: 0.8839 - val_loss: 0.7046 - val_accuracy: 0.7886\n",
            "Epoch 469/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2736 - accuracy: 0.8819 - val_loss: 0.7930 - val_accuracy: 0.7642\n",
            "Epoch 470/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2627 - accuracy: 0.8798 - val_loss: 0.7656 - val_accuracy: 0.7561\n",
            "Epoch 471/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2630 - accuracy: 0.8859 - val_loss: 0.8088 - val_accuracy: 0.7480\n",
            "Epoch 472/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2757 - accuracy: 0.8778 - val_loss: 0.8212 - val_accuracy: 0.7154\n",
            "Epoch 473/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2557 - accuracy: 0.8839 - val_loss: 0.7980 - val_accuracy: 0.7724\n",
            "Epoch 474/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 0.8921 - val_loss: 0.7185 - val_accuracy: 0.7480\n",
            "Epoch 475/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2536 - accuracy: 0.9002 - val_loss: 0.7311 - val_accuracy: 0.7561\n",
            "Epoch 476/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2744 - accuracy: 0.8859 - val_loss: 0.6855 - val_accuracy: 0.7642\n",
            "Epoch 477/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.8819 - val_loss: 0.8033 - val_accuracy: 0.7480\n",
            "Epoch 478/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2611 - accuracy: 0.8880 - val_loss: 0.8973 - val_accuracy: 0.7236\n",
            "Epoch 479/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 0.8900 - val_loss: 0.7456 - val_accuracy: 0.7317\n",
            "Epoch 480/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2484 - accuracy: 0.8859 - val_loss: 0.7955 - val_accuracy: 0.7154\n",
            "Epoch 481/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.8900 - val_loss: 0.7406 - val_accuracy: 0.7398\n",
            "Epoch 482/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.9063 - val_loss: 0.7225 - val_accuracy: 0.7561\n",
            "Epoch 483/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.8900 - val_loss: 0.7297 - val_accuracy: 0.7724\n",
            "Epoch 484/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2407 - accuracy: 0.8961 - val_loss: 0.8367 - val_accuracy: 0.7398\n",
            "Epoch 485/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.8859 - val_loss: 0.7354 - val_accuracy: 0.7967\n",
            "Epoch 486/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2415 - accuracy: 0.9104 - val_loss: 0.7408 - val_accuracy: 0.7724\n",
            "Epoch 487/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.8839 - val_loss: 0.7774 - val_accuracy: 0.7317\n",
            "Epoch 488/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2605 - accuracy: 0.8839 - val_loss: 0.7143 - val_accuracy: 0.7724\n",
            "Epoch 489/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.8921 - val_loss: 0.7995 - val_accuracy: 0.7561\n",
            "Epoch 490/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2293 - accuracy: 0.9124 - val_loss: 0.7859 - val_accuracy: 0.7480\n",
            "Epoch 491/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2479 - accuracy: 0.8900 - val_loss: 0.9114 - val_accuracy: 0.7398\n",
            "Epoch 492/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.8839 - val_loss: 0.8249 - val_accuracy: 0.7642\n",
            "Epoch 493/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2435 - accuracy: 0.8982 - val_loss: 0.7811 - val_accuracy: 0.7561\n",
            "Epoch 494/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2813 - accuracy: 0.8635 - val_loss: 0.6902 - val_accuracy: 0.7886\n",
            "Epoch 495/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2421 - accuracy: 0.9104 - val_loss: 0.8148 - val_accuracy: 0.7561\n",
            "Epoch 496/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2452 - accuracy: 0.8798 - val_loss: 0.7823 - val_accuracy: 0.7642\n",
            "Epoch 497/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2573 - accuracy: 0.8961 - val_loss: 0.7730 - val_accuracy: 0.7480\n",
            "Epoch 498/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2359 - accuracy: 0.8900 - val_loss: 0.8325 - val_accuracy: 0.7642\n",
            "Epoch 499/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2385 - accuracy: 0.8880 - val_loss: 0.7745 - val_accuracy: 0.7073\n",
            "Epoch 500/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.8961 - val_loss: 0.8158 - val_accuracy: 0.7561\n",
            "Epoch 501/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.9022 - val_loss: 0.7648 - val_accuracy: 0.7480\n",
            "Epoch 502/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2303 - accuracy: 0.9145 - val_loss: 0.7782 - val_accuracy: 0.7398\n",
            "Epoch 503/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2413 - accuracy: 0.8859 - val_loss: 0.7458 - val_accuracy: 0.7480\n",
            "Epoch 504/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2320 - accuracy: 0.9063 - val_loss: 0.8404 - val_accuracy: 0.7154\n",
            "Epoch 505/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2325 - accuracy: 0.9022 - val_loss: 0.8304 - val_accuracy: 0.6992\n",
            "Epoch 506/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2609 - accuracy: 0.8778 - val_loss: 0.9150 - val_accuracy: 0.7154\n",
            "Epoch 507/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2367 - accuracy: 0.8839 - val_loss: 0.8129 - val_accuracy: 0.7236\n",
            "Epoch 508/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2618 - accuracy: 0.8778 - val_loss: 0.8132 - val_accuracy: 0.7642\n",
            "Epoch 509/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2411 - accuracy: 0.8798 - val_loss: 0.8207 - val_accuracy: 0.7561\n",
            "Epoch 510/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8941 - val_loss: 0.7299 - val_accuracy: 0.7724\n",
            "Epoch 511/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2413 - accuracy: 0.8921 - val_loss: 0.7816 - val_accuracy: 0.7480\n",
            "Epoch 512/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2362 - accuracy: 0.8982 - val_loss: 0.8577 - val_accuracy: 0.7317\n",
            "Epoch 513/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8982 - val_loss: 0.7751 - val_accuracy: 0.7642\n",
            "Epoch 514/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2189 - accuracy: 0.9084 - val_loss: 0.7506 - val_accuracy: 0.7642\n",
            "Epoch 515/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2350 - accuracy: 0.8961 - val_loss: 0.8580 - val_accuracy: 0.7398\n",
            "Epoch 516/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2617 - accuracy: 0.8941 - val_loss: 0.8102 - val_accuracy: 0.7480\n",
            "Epoch 517/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2360 - accuracy: 0.9022 - val_loss: 0.9703 - val_accuracy: 0.7398\n",
            "Epoch 518/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8941 - val_loss: 0.8747 - val_accuracy: 0.7073\n",
            "Epoch 519/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2068 - accuracy: 0.9145 - val_loss: 0.8948 - val_accuracy: 0.7154\n",
            "Epoch 520/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2423 - accuracy: 0.9022 - val_loss: 0.7789 - val_accuracy: 0.7480\n",
            "Epoch 521/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2556 - accuracy: 0.8819 - val_loss: 0.9236 - val_accuracy: 0.7073\n",
            "Epoch 522/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2335 - accuracy: 0.9002 - val_loss: 0.8178 - val_accuracy: 0.7642\n",
            "Epoch 523/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2415 - accuracy: 0.8921 - val_loss: 0.8206 - val_accuracy: 0.7642\n",
            "Epoch 524/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2105 - accuracy: 0.9084 - val_loss: 0.8837 - val_accuracy: 0.7073\n",
            "Epoch 525/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2216 - accuracy: 0.9002 - val_loss: 0.8347 - val_accuracy: 0.7642\n",
            "Epoch 526/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2121 - accuracy: 0.8961 - val_loss: 0.8513 - val_accuracy: 0.6829\n",
            "Epoch 527/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2343 - accuracy: 0.9246 - val_loss: 0.8889 - val_accuracy: 0.7480\n",
            "Epoch 528/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2441 - accuracy: 0.9022 - val_loss: 0.8305 - val_accuracy: 0.7236\n",
            "Epoch 529/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2280 - accuracy: 0.9145 - val_loss: 0.8491 - val_accuracy: 0.7398\n",
            "Epoch 530/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2106 - accuracy: 0.9043 - val_loss: 0.8840 - val_accuracy: 0.7398\n",
            "Epoch 531/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2129 - accuracy: 0.9084 - val_loss: 0.8442 - val_accuracy: 0.7398\n",
            "Epoch 532/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2304 - accuracy: 0.9104 - val_loss: 0.8598 - val_accuracy: 0.7561\n",
            "Epoch 533/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2221 - accuracy: 0.9104 - val_loss: 0.8327 - val_accuracy: 0.7886\n",
            "Epoch 534/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2398 - accuracy: 0.8798 - val_loss: 0.8765 - val_accuracy: 0.7642\n",
            "Epoch 535/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2136 - accuracy: 0.9145 - val_loss: 0.9698 - val_accuracy: 0.7398\n",
            "Epoch 536/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2385 - accuracy: 0.9063 - val_loss: 0.8542 - val_accuracy: 0.7642\n",
            "Epoch 537/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2059 - accuracy: 0.9104 - val_loss: 1.0224 - val_accuracy: 0.7398\n",
            "Epoch 538/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2288 - accuracy: 0.9002 - val_loss: 0.8929 - val_accuracy: 0.7236\n",
            "Epoch 539/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2190 - accuracy: 0.9022 - val_loss: 0.8429 - val_accuracy: 0.7480\n",
            "Epoch 540/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 0.9267 - val_loss: 0.9136 - val_accuracy: 0.7398\n",
            "Epoch 541/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2024 - accuracy: 0.9145 - val_loss: 0.9920 - val_accuracy: 0.7398\n",
            "Epoch 542/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2136 - accuracy: 0.9084 - val_loss: 0.8575 - val_accuracy: 0.7317\n",
            "Epoch 543/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2193 - accuracy: 0.9104 - val_loss: 0.8833 - val_accuracy: 0.7154\n",
            "Epoch 544/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2236 - accuracy: 0.8941 - val_loss: 0.9023 - val_accuracy: 0.7480\n",
            "Epoch 545/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2165 - accuracy: 0.9084 - val_loss: 0.9318 - val_accuracy: 0.7317\n",
            "Epoch 546/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1991 - accuracy: 0.9226 - val_loss: 1.0175 - val_accuracy: 0.7480\n",
            "Epoch 547/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2140 - accuracy: 0.9104 - val_loss: 0.9770 - val_accuracy: 0.7236\n",
            "Epoch 548/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2183 - accuracy: 0.9226 - val_loss: 0.9419 - val_accuracy: 0.7236\n",
            "Epoch 549/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2238 - accuracy: 0.9124 - val_loss: 0.8825 - val_accuracy: 0.7398\n",
            "Epoch 550/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2002 - accuracy: 0.9185 - val_loss: 1.0506 - val_accuracy: 0.6911\n",
            "Epoch 551/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2030 - accuracy: 0.9063 - val_loss: 0.9529 - val_accuracy: 0.7480\n",
            "Epoch 552/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2173 - accuracy: 0.9043 - val_loss: 0.9451 - val_accuracy: 0.7805\n",
            "Epoch 553/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2132 - accuracy: 0.9104 - val_loss: 0.9563 - val_accuracy: 0.7561\n",
            "Epoch 554/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2029 - accuracy: 0.9063 - val_loss: 0.9872 - val_accuracy: 0.7480\n",
            "Epoch 555/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2207 - accuracy: 0.9043 - val_loss: 0.9801 - val_accuracy: 0.7398\n",
            "Epoch 556/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2053 - accuracy: 0.9124 - val_loss: 1.0365 - val_accuracy: 0.6748\n",
            "Epoch 557/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1932 - accuracy: 0.9206 - val_loss: 0.8602 - val_accuracy: 0.7236\n",
            "Epoch 558/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2123 - accuracy: 0.9287 - val_loss: 0.9260 - val_accuracy: 0.7317\n",
            "Epoch 559/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2155 - accuracy: 0.9226 - val_loss: 1.0718 - val_accuracy: 0.7154\n",
            "Epoch 560/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2387 - accuracy: 0.9084 - val_loss: 1.0118 - val_accuracy: 0.7154\n",
            "Epoch 561/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1894 - accuracy: 0.9267 - val_loss: 0.9810 - val_accuracy: 0.7724\n",
            "Epoch 562/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2187 - accuracy: 0.9022 - val_loss: 0.9662 - val_accuracy: 0.7236\n",
            "Epoch 563/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2015 - accuracy: 0.9043 - val_loss: 0.9622 - val_accuracy: 0.7073\n",
            "Epoch 564/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2123 - accuracy: 0.9145 - val_loss: 0.9071 - val_accuracy: 0.7317\n",
            "Epoch 565/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2227 - accuracy: 0.9043 - val_loss: 1.0075 - val_accuracy: 0.7317\n",
            "Epoch 566/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2067 - accuracy: 0.9084 - val_loss: 0.8506 - val_accuracy: 0.7480\n",
            "Epoch 567/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2233 - accuracy: 0.9002 - val_loss: 0.9304 - val_accuracy: 0.7317\n",
            "Epoch 568/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1940 - accuracy: 0.9206 - val_loss: 0.9909 - val_accuracy: 0.7398\n",
            "Epoch 569/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2110 - accuracy: 0.9124 - val_loss: 0.9590 - val_accuracy: 0.7642\n",
            "Epoch 570/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1911 - accuracy: 0.9206 - val_loss: 0.8841 - val_accuracy: 0.7480\n",
            "Epoch 571/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1967 - accuracy: 0.9104 - val_loss: 0.9553 - val_accuracy: 0.7317\n",
            "Epoch 572/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.2053 - accuracy: 0.9104 - val_loss: 0.9356 - val_accuracy: 0.7805\n",
            "Epoch 573/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.1936 - accuracy: 0.9165 - val_loss: 1.0404 - val_accuracy: 0.7724\n",
            "Epoch 574/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2072 - accuracy: 0.9124 - val_loss: 1.0149 - val_accuracy: 0.7642\n",
            "Epoch 575/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1866 - accuracy: 0.9185 - val_loss: 1.1154 - val_accuracy: 0.7236\n",
            "Epoch 576/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2342 - accuracy: 0.9104 - val_loss: 1.0014 - val_accuracy: 0.7561\n",
            "Epoch 577/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.2052 - accuracy: 0.9226 - val_loss: 1.0919 - val_accuracy: 0.7561\n",
            "Epoch 578/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1886 - accuracy: 0.9104 - val_loss: 1.1259 - val_accuracy: 0.7154\n",
            "Epoch 579/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2153 - accuracy: 0.9226 - val_loss: 0.9498 - val_accuracy: 0.7398\n",
            "Epoch 580/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1794 - accuracy: 0.9287 - val_loss: 1.0467 - val_accuracy: 0.7154\n",
            "Epoch 581/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1874 - accuracy: 0.9206 - val_loss: 0.9925 - val_accuracy: 0.7154\n",
            "Epoch 582/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1979 - accuracy: 0.9308 - val_loss: 1.0425 - val_accuracy: 0.7317\n",
            "Epoch 583/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1948 - accuracy: 0.9165 - val_loss: 1.0453 - val_accuracy: 0.7724\n",
            "Epoch 584/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1728 - accuracy: 0.9328 - val_loss: 0.9428 - val_accuracy: 0.7561\n",
            "Epoch 585/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1871 - accuracy: 0.9308 - val_loss: 1.0696 - val_accuracy: 0.7642\n",
            "Epoch 586/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1882 - accuracy: 0.9165 - val_loss: 1.0143 - val_accuracy: 0.7236\n",
            "Epoch 587/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.1851 - accuracy: 0.9206 - val_loss: 1.0692 - val_accuracy: 0.7561\n",
            "Epoch 588/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.1788 - accuracy: 0.9246 - val_loss: 1.0509 - val_accuracy: 0.6992\n",
            "Epoch 589/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.1710 - accuracy: 0.9246 - val_loss: 1.0349 - val_accuracy: 0.7317\n",
            "Epoch 590/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2137 - accuracy: 0.9043 - val_loss: 1.0836 - val_accuracy: 0.7561\n",
            "Epoch 591/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1763 - accuracy: 0.9206 - val_loss: 1.0447 - val_accuracy: 0.7398\n",
            "Epoch 592/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2095 - accuracy: 0.9063 - val_loss: 1.0455 - val_accuracy: 0.6992\n",
            "Epoch 593/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1728 - accuracy: 0.9267 - val_loss: 1.0983 - val_accuracy: 0.7480\n",
            "Epoch 594/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1823 - accuracy: 0.9185 - val_loss: 1.1349 - val_accuracy: 0.7317\n",
            "Epoch 595/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.9185 - val_loss: 1.0465 - val_accuracy: 0.7154\n",
            "Epoch 596/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1522 - accuracy: 0.9348 - val_loss: 1.1440 - val_accuracy: 0.7154\n",
            "Epoch 597/750\n",
            "123/123 [==============================] - 1s 4ms/step - loss: 0.1945 - accuracy: 0.9246 - val_loss: 1.0931 - val_accuracy: 0.7561\n",
            "Epoch 598/750\n",
            "123/123 [==============================] - 1s 5ms/step - loss: 0.1686 - accuracy: 0.9389 - val_loss: 1.1372 - val_accuracy: 0.7317\n",
            "Epoch 599/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1830 - accuracy: 0.9267 - val_loss: 1.0828 - val_accuracy: 0.7398\n",
            "Epoch 600/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1967 - accuracy: 0.9206 - val_loss: 1.0075 - val_accuracy: 0.6992\n",
            "Epoch 601/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.1923 - accuracy: 0.9226 - val_loss: 1.0780 - val_accuracy: 0.7561\n",
            "Epoch 602/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.1739 - accuracy: 0.9246 - val_loss: 1.1025 - val_accuracy: 0.7805\n",
            "Epoch 603/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.1729 - accuracy: 0.9287 - val_loss: 1.1314 - val_accuracy: 0.7154\n",
            "Epoch 604/750\n",
            "123/123 [==============================] - 1s 5ms/step - loss: 0.1925 - accuracy: 0.9226 - val_loss: 1.0975 - val_accuracy: 0.7561\n",
            "Epoch 605/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1847 - accuracy: 0.9165 - val_loss: 1.0559 - val_accuracy: 0.7073\n",
            "Epoch 606/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1719 - accuracy: 0.9328 - val_loss: 1.2013 - val_accuracy: 0.7561\n",
            "Epoch 607/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.1782 - accuracy: 0.9185 - val_loss: 1.1780 - val_accuracy: 0.6911\n",
            "Epoch 608/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1771 - accuracy: 0.9246 - val_loss: 1.0712 - val_accuracy: 0.7154\n",
            "Epoch 609/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1713 - accuracy: 0.9348 - val_loss: 1.1188 - val_accuracy: 0.7480\n",
            "Epoch 610/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2077 - accuracy: 0.9267 - val_loss: 1.0913 - val_accuracy: 0.7317\n",
            "Epoch 611/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.1642 - accuracy: 0.9348 - val_loss: 1.2331 - val_accuracy: 0.7398\n",
            "Epoch 612/750\n",
            "123/123 [==============================] - 1s 4ms/step - loss: 0.1506 - accuracy: 0.9450 - val_loss: 1.3472 - val_accuracy: 0.7154\n",
            "Epoch 613/750\n",
            "123/123 [==============================] - 1s 6ms/step - loss: 0.1841 - accuracy: 0.9165 - val_loss: 1.1733 - val_accuracy: 0.7398\n",
            "Epoch 614/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1960 - accuracy: 0.9145 - val_loss: 1.0793 - val_accuracy: 0.7236\n",
            "Epoch 615/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1756 - accuracy: 0.9348 - val_loss: 1.1332 - val_accuracy: 0.6992\n",
            "Epoch 616/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9308 - val_loss: 1.2088 - val_accuracy: 0.7236\n",
            "Epoch 617/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2055 - accuracy: 0.9104 - val_loss: 1.1687 - val_accuracy: 0.7642\n",
            "Epoch 618/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2401 - accuracy: 0.9063 - val_loss: 1.1402 - val_accuracy: 0.7561\n",
            "Epoch 619/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1577 - accuracy: 0.9287 - val_loss: 1.1496 - val_accuracy: 0.7073\n",
            "Epoch 620/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1634 - accuracy: 0.9308 - val_loss: 1.1248 - val_accuracy: 0.7317\n",
            "Epoch 621/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2822 - accuracy: 0.8798 - val_loss: 1.1261 - val_accuracy: 0.7398\n",
            "Epoch 622/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.9267 - val_loss: 1.1165 - val_accuracy: 0.7154\n",
            "Epoch 623/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1625 - accuracy: 0.9348 - val_loss: 1.2561 - val_accuracy: 0.7480\n",
            "Epoch 624/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1650 - accuracy: 0.9328 - val_loss: 1.2003 - val_accuracy: 0.7154\n",
            "Epoch 625/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9430 - val_loss: 1.2659 - val_accuracy: 0.7398\n",
            "Epoch 626/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9348 - val_loss: 1.1537 - val_accuracy: 0.7805\n",
            "Epoch 627/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.1470 - accuracy: 0.9348 - val_loss: 1.2260 - val_accuracy: 0.7236\n",
            "Epoch 628/750\n",
            "123/123 [==============================] - 1s 5ms/step - loss: 0.1738 - accuracy: 0.9246 - val_loss: 1.2037 - val_accuracy: 0.7480\n",
            "Epoch 629/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1572 - accuracy: 0.9369 - val_loss: 1.1591 - val_accuracy: 0.7480\n",
            "Epoch 630/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1219 - accuracy: 0.9491 - val_loss: 1.1236 - val_accuracy: 0.7398\n",
            "Epoch 631/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.1511 - accuracy: 0.9348 - val_loss: 1.2475 - val_accuracy: 0.7236\n",
            "Epoch 632/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.1820 - accuracy: 0.9328 - val_loss: 1.2480 - val_accuracy: 0.7480\n",
            "Epoch 633/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.1504 - accuracy: 0.9430 - val_loss: 1.2792 - val_accuracy: 0.7317\n",
            "Epoch 634/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.1499 - accuracy: 0.9369 - val_loss: 1.1835 - val_accuracy: 0.7073\n",
            "Epoch 635/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1529 - accuracy: 0.9369 - val_loss: 1.3172 - val_accuracy: 0.7154\n",
            "Epoch 636/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9369 - val_loss: 1.2308 - val_accuracy: 0.7480\n",
            "Epoch 637/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1199 - accuracy: 0.9511 - val_loss: 1.2707 - val_accuracy: 0.7073\n",
            "Epoch 638/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1345 - accuracy: 0.9572 - val_loss: 1.3256 - val_accuracy: 0.7480\n",
            "Epoch 639/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1410 - accuracy: 0.9430 - val_loss: 1.2421 - val_accuracy: 0.7154\n",
            "Epoch 640/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1331 - accuracy: 0.9389 - val_loss: 1.2517 - val_accuracy: 0.7724\n",
            "Epoch 641/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1561 - accuracy: 0.9409 - val_loss: 1.3421 - val_accuracy: 0.7480\n",
            "Epoch 642/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1579 - accuracy: 0.9287 - val_loss: 1.2581 - val_accuracy: 0.7561\n",
            "Epoch 643/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1934 - accuracy: 0.9185 - val_loss: 1.0800 - val_accuracy: 0.7398\n",
            "Epoch 644/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1916 - accuracy: 0.9104 - val_loss: 1.2832 - val_accuracy: 0.7236\n",
            "Epoch 645/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1364 - accuracy: 0.9572 - val_loss: 1.2934 - val_accuracy: 0.7642\n",
            "Epoch 646/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1725 - accuracy: 0.9287 - val_loss: 1.3234 - val_accuracy: 0.7480\n",
            "Epoch 647/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1533 - accuracy: 0.9430 - val_loss: 1.3403 - val_accuracy: 0.7236\n",
            "Epoch 648/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.9613 - val_loss: 1.2829 - val_accuracy: 0.7236\n",
            "Epoch 649/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1538 - accuracy: 0.9389 - val_loss: 1.2863 - val_accuracy: 0.7154\n",
            "Epoch 650/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1809 - accuracy: 0.9246 - val_loss: 1.3007 - val_accuracy: 0.7480\n",
            "Epoch 651/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1559 - accuracy: 0.9409 - val_loss: 1.4571 - val_accuracy: 0.6748\n",
            "Epoch 652/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.1276 - accuracy: 0.9552 - val_loss: 1.2426 - val_accuracy: 0.7154\n",
            "Epoch 653/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9369 - val_loss: 1.3471 - val_accuracy: 0.7561\n",
            "Epoch 654/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1575 - accuracy: 0.9308 - val_loss: 1.3828 - val_accuracy: 0.7480\n",
            "Epoch 655/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1411 - accuracy: 0.9450 - val_loss: 1.3648 - val_accuracy: 0.6992\n",
            "Epoch 656/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.9552 - val_loss: 1.3263 - val_accuracy: 0.7480\n",
            "Epoch 657/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1329 - accuracy: 0.9511 - val_loss: 1.3858 - val_accuracy: 0.7154\n",
            "Epoch 658/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1241 - accuracy: 0.9572 - val_loss: 1.3860 - val_accuracy: 0.7317\n",
            "Epoch 659/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1760 - accuracy: 0.9369 - val_loss: 1.3863 - val_accuracy: 0.7154\n",
            "Epoch 660/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1417 - accuracy: 0.9450 - val_loss: 1.4150 - val_accuracy: 0.7154\n",
            "Epoch 661/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2305 - accuracy: 0.9226 - val_loss: 1.4054 - val_accuracy: 0.7317\n",
            "Epoch 662/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.9389 - val_loss: 1.3613 - val_accuracy: 0.7317\n",
            "Epoch 663/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9409 - val_loss: 1.3812 - val_accuracy: 0.7154\n",
            "Epoch 664/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1336 - accuracy: 0.9511 - val_loss: 1.3745 - val_accuracy: 0.7073\n",
            "Epoch 665/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1495 - accuracy: 0.9369 - val_loss: 1.3294 - val_accuracy: 0.7480\n",
            "Epoch 666/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1095 - accuracy: 0.9633 - val_loss: 1.4148 - val_accuracy: 0.7154\n",
            "Epoch 667/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1707 - accuracy: 0.9328 - val_loss: 1.4108 - val_accuracy: 0.6911\n",
            "Epoch 668/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1396 - accuracy: 0.9389 - val_loss: 1.2480 - val_accuracy: 0.7561\n",
            "Epoch 669/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1377 - accuracy: 0.9450 - val_loss: 1.4272 - val_accuracy: 0.7480\n",
            "Epoch 670/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1181 - accuracy: 0.9572 - val_loss: 1.3636 - val_accuracy: 0.7398\n",
            "Epoch 671/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1227 - accuracy: 0.9572 - val_loss: 1.4362 - val_accuracy: 0.7561\n",
            "Epoch 672/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1145 - accuracy: 0.9389 - val_loss: 1.4625 - val_accuracy: 0.7317\n",
            "Epoch 673/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1438 - accuracy: 0.9511 - val_loss: 1.4717 - val_accuracy: 0.7398\n",
            "Epoch 674/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1646 - accuracy: 0.9389 - val_loss: 1.3656 - val_accuracy: 0.7480\n",
            "Epoch 675/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1388 - accuracy: 0.9409 - val_loss: 1.3919 - val_accuracy: 0.7317\n",
            "Epoch 676/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1329 - accuracy: 0.9369 - val_loss: 1.4209 - val_accuracy: 0.7480\n",
            "Epoch 677/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1273 - accuracy: 0.9430 - val_loss: 1.3993 - val_accuracy: 0.7317\n",
            "Epoch 678/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1245 - accuracy: 0.9450 - val_loss: 1.4428 - val_accuracy: 0.7154\n",
            "Epoch 679/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2177 - accuracy: 0.9084 - val_loss: 1.5806 - val_accuracy: 0.7154\n",
            "Epoch 680/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1720 - accuracy: 0.9206 - val_loss: 1.5533 - val_accuracy: 0.7073\n",
            "Epoch 681/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1583 - accuracy: 0.9430 - val_loss: 1.3578 - val_accuracy: 0.7317\n",
            "Epoch 682/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2000 - accuracy: 0.9145 - val_loss: 1.4290 - val_accuracy: 0.6667\n",
            "Epoch 683/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1538 - accuracy: 0.9308 - val_loss: 1.3064 - val_accuracy: 0.7236\n",
            "Epoch 684/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1654 - accuracy: 0.9226 - val_loss: 1.4047 - val_accuracy: 0.7154\n",
            "Epoch 685/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1845 - accuracy: 0.9145 - val_loss: 1.3448 - val_accuracy: 0.7724\n",
            "Epoch 686/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1356 - accuracy: 0.9511 - val_loss: 1.3633 - val_accuracy: 0.7236\n",
            "Epoch 687/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1072 - accuracy: 0.9572 - val_loss: 1.3907 - val_accuracy: 0.7480\n",
            "Epoch 688/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1008 - accuracy: 0.9613 - val_loss: 1.6487 - val_accuracy: 0.6992\n",
            "Epoch 689/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.9450 - val_loss: 1.3877 - val_accuracy: 0.7480\n",
            "Epoch 690/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1115 - accuracy: 0.9613 - val_loss: 1.4921 - val_accuracy: 0.7317\n",
            "Epoch 691/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1022 - accuracy: 0.9613 - val_loss: 1.5491 - val_accuracy: 0.7398\n",
            "Epoch 692/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0989 - accuracy: 0.9633 - val_loss: 1.4692 - val_accuracy: 0.7154\n",
            "Epoch 693/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1035 - accuracy: 0.9572 - val_loss: 1.4594 - val_accuracy: 0.6992\n",
            "Epoch 694/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1042 - accuracy: 0.9654 - val_loss: 1.6081 - val_accuracy: 0.7073\n",
            "Epoch 695/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9369 - val_loss: 1.6628 - val_accuracy: 0.7236\n",
            "Epoch 696/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2202 - accuracy: 0.9063 - val_loss: 1.4581 - val_accuracy: 0.7236\n",
            "Epoch 697/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1228 - accuracy: 0.9532 - val_loss: 1.3992 - val_accuracy: 0.7317\n",
            "Epoch 698/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.9511 - val_loss: 1.5629 - val_accuracy: 0.6992\n",
            "Epoch 699/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1287 - accuracy: 0.9369 - val_loss: 1.4362 - val_accuracy: 0.7236\n",
            "Epoch 700/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1631 - accuracy: 0.9328 - val_loss: 1.3623 - val_accuracy: 0.7236\n",
            "Epoch 701/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0968 - accuracy: 0.9491 - val_loss: 1.4568 - val_accuracy: 0.7398\n",
            "Epoch 702/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1202 - accuracy: 0.9450 - val_loss: 1.4823 - val_accuracy: 0.7236\n",
            "Epoch 703/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1658 - accuracy: 0.9287 - val_loss: 1.4903 - val_accuracy: 0.7317\n",
            "Epoch 704/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.1084 - accuracy: 0.9593 - val_loss: 1.5144 - val_accuracy: 0.7236\n",
            "Epoch 705/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.0972 - accuracy: 0.9613 - val_loss: 1.5848 - val_accuracy: 0.6992\n",
            "Epoch 706/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1163 - accuracy: 0.9613 - val_loss: 1.4149 - val_accuracy: 0.7480\n",
            "Epoch 707/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2796 - accuracy: 0.9063 - val_loss: 1.4592 - val_accuracy: 0.6911\n",
            "Epoch 708/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1568 - accuracy: 0.9348 - val_loss: 1.4570 - val_accuracy: 0.7154\n",
            "Epoch 709/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0937 - accuracy: 0.9695 - val_loss: 1.5172 - val_accuracy: 0.7236\n",
            "Epoch 710/750\n",
            "123/123 [==============================] - 1s 4ms/step - loss: 0.0919 - accuracy: 0.9633 - val_loss: 1.6467 - val_accuracy: 0.6829\n",
            "Epoch 711/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0912 - accuracy: 0.9593 - val_loss: 1.5222 - val_accuracy: 0.7154\n",
            "Epoch 712/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1045 - accuracy: 0.9674 - val_loss: 1.5118 - val_accuracy: 0.7398\n",
            "Epoch 713/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0977 - accuracy: 0.9593 - val_loss: 1.5070 - val_accuracy: 0.6992\n",
            "Epoch 714/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0991 - accuracy: 0.9674 - val_loss: 1.4593 - val_accuracy: 0.7073\n",
            "Epoch 715/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1885 - accuracy: 0.9287 - val_loss: 1.6565 - val_accuracy: 0.7154\n",
            "Epoch 716/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2067 - accuracy: 0.9206 - val_loss: 1.5516 - val_accuracy: 0.7154\n",
            "Epoch 717/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1028 - accuracy: 0.9511 - val_loss: 1.5082 - val_accuracy: 0.7073\n",
            "Epoch 718/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.1604 - accuracy: 0.9409 - val_loss: 1.6043 - val_accuracy: 0.6748\n",
            "Epoch 719/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1306 - accuracy: 0.9470 - val_loss: 1.5541 - val_accuracy: 0.7317\n",
            "Epoch 720/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.1200 - accuracy: 0.9450 - val_loss: 1.5683 - val_accuracy: 0.7398\n",
            "Epoch 721/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.0937 - accuracy: 0.9654 - val_loss: 1.5327 - val_accuracy: 0.7480\n",
            "Epoch 722/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.0743 - accuracy: 0.9695 - val_loss: 1.5655 - val_accuracy: 0.7398\n",
            "Epoch 723/750\n",
            "123/123 [==============================] - 1s 5ms/step - loss: 0.1526 - accuracy: 0.9470 - val_loss: 1.6471 - val_accuracy: 0.6829\n",
            "Epoch 724/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.1288 - accuracy: 0.9450 - val_loss: 1.6404 - val_accuracy: 0.7480\n",
            "Epoch 725/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1095 - accuracy: 0.9593 - val_loss: 1.5756 - val_accuracy: 0.7398\n",
            "Epoch 726/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0852 - accuracy: 0.9695 - val_loss: 1.5844 - val_accuracy: 0.7073\n",
            "Epoch 727/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1209 - accuracy: 0.9532 - val_loss: 1.5856 - val_accuracy: 0.6992\n",
            "Epoch 728/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0703 - accuracy: 0.9715 - val_loss: 1.6175 - val_accuracy: 0.7317\n",
            "Epoch 729/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.0842 - accuracy: 0.9715 - val_loss: 1.7028 - val_accuracy: 0.7073\n",
            "Epoch 730/750\n",
            "123/123 [==============================] - 1s 9ms/step - loss: 0.1486 - accuracy: 0.9491 - val_loss: 1.4962 - val_accuracy: 0.6992\n",
            "Epoch 731/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9572 - val_loss: 1.5646 - val_accuracy: 0.7724\n",
            "Epoch 732/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0740 - accuracy: 0.9756 - val_loss: 1.5825 - val_accuracy: 0.7642\n",
            "Epoch 733/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.9756 - val_loss: 1.6903 - val_accuracy: 0.7154\n",
            "Epoch 734/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.1117 - accuracy: 0.9593 - val_loss: 1.7338 - val_accuracy: 0.6748\n",
            "Epoch 735/750\n",
            "123/123 [==============================] - 1s 4ms/step - loss: 0.1154 - accuracy: 0.9532 - val_loss: 1.8153 - val_accuracy: 0.7398\n",
            "Epoch 736/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.1482 - accuracy: 0.9389 - val_loss: 1.7416 - val_accuracy: 0.7154\n",
            "Epoch 737/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.2438 - accuracy: 0.9124 - val_loss: 1.6352 - val_accuracy: 0.6911\n",
            "Epoch 738/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0826 - accuracy: 0.9715 - val_loss: 1.7346 - val_accuracy: 0.6829\n",
            "Epoch 739/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0961 - accuracy: 0.9511 - val_loss: 1.6847 - val_accuracy: 0.7236\n",
            "Epoch 740/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0900 - accuracy: 0.9674 - val_loss: 1.6590 - val_accuracy: 0.7154\n",
            "Epoch 741/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0852 - accuracy: 0.9633 - val_loss: 1.6463 - val_accuracy: 0.7398\n",
            "Epoch 742/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1379 - accuracy: 0.9348 - val_loss: 1.7278 - val_accuracy: 0.7073\n",
            "Epoch 743/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.0936 - accuracy: 0.9674 - val_loss: 1.5787 - val_accuracy: 0.7398\n",
            "Epoch 744/750\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.9715 - val_loss: 1.7290 - val_accuracy: 0.6911\n",
            "Epoch 745/750\n",
            "123/123 [==============================] - 1s 5ms/step - loss: 0.1224 - accuracy: 0.9532 - val_loss: 1.7076 - val_accuracy: 0.7317\n",
            "Epoch 746/750\n",
            "123/123 [==============================] - 1s 4ms/step - loss: 0.0864 - accuracy: 0.9572 - val_loss: 1.6150 - val_accuracy: 0.7236\n",
            "Epoch 747/750\n",
            "123/123 [==============================] - 1s 5ms/step - loss: 0.1715 - accuracy: 0.9246 - val_loss: 1.5545 - val_accuracy: 0.7154\n",
            "Epoch 748/750\n",
            "123/123 [==============================] - 1s 7ms/step - loss: 0.1227 - accuracy: 0.9511 - val_loss: 1.5410 - val_accuracy: 0.7236\n",
            "Epoch 749/750\n",
            "123/123 [==============================] - 1s 5ms/step - loss: 0.1650 - accuracy: 0.9409 - val_loss: 1.6701 - val_accuracy: 0.6992\n",
            "Epoch 750/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2127 - accuracy: 0.9185 - val_loss: 1.6008 - val_accuracy: 0.6992\n"
          ]
        }
      ]
    }
  ]
}